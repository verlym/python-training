{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Exploratory Data Analysis (EDA)** is an essential initial step for data professionals to deeply understand datasets and uncover valuable insights. It involves using a diverse array of tools and techniques, with data visualization playing a pivotal role.\n",
        "\n",
        "Through EDA, we gain a comprehensive view of data characteristics, identify relationships between variables, and formulate meaningful research questions. It serves as a powerful method to detect trends, patterns, outliers, and anomalies, paving the way for informed decision-making.\n",
        "\n",
        "Originated by the pioneering American mathematician John Tukey in the 1970s, EDA remains indispensable today in the data exploration phase, preceding more advanced analytics and machine learning tasks.\n"
      ],
      "metadata": {
        "id": "p4UuksuAhkpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this workshop, we will be exploring this concept further by conducting EDA on a dataset using Python. Aside from base Python, we shall also be making use of 4 Python modules for our EDA project:**\n",
        "\n",
        "- **Numpy**: A core Python library for scientific computing using high-performance arrays.\n",
        "- **Pandas**: A fast and powerful data analysis and manipulation tool.\n",
        "- **Matplotlib**: A comprehensive library for creating visualizations in Python.\n",
        "- **Seaborn**: Another data visualization library built on top of Matplotlib.\n",
        "\n",
        "We’ll be using a dataset that contains client information for an insurance company. Each of the 10,000 rows in the dataset corresponds to a single client, with 19 variables recording a variety of client-specific information.\n",
        "``\n"
      ],
      "metadata": {
        "id": "drtRGvYHibcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Relevant Libraries\n",
        "\n",
        "Before loading the dataset, we will need to first import all the relevant libraries. If you don’t have them installed already, you can do so by using the `pip install` command.\n"
      ],
      "metadata": {
        "id": "DMv2qwMuiicQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write code here"
      ],
      "metadata": {
        "id": "LcKBlaaIi3uN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data\n",
        "\n",
        "We can now load the dataset into pandas using the `read_csv()` function. This converts the CSV file into a Pandas dataframe."
      ],
      "metadata": {
        "id": "pOlkYzjCi_Ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read in the csv file and convert to a Pandas dataframe\n",
        "#write code here"
      ],
      "metadata": {
        "id": "mIKsUWFJjFlQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Viewing the Dataframe\n",
        "\n",
        "We can get a quick sense of the size of our dataset by using the `shape` method. This returns a tuple with the number of rows and columns in the dataset.\n"
      ],
      "metadata": {
        "id": "KpdmHfUyjNPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Return number of rows and columns\n",
        "#write code here"
      ],
      "metadata": {
        "id": "L2CpIck-jQ47"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's preview the first 5 rows.\n",
        "\n"
      ],
      "metadata": {
        "id": "-Zvyy47EjT4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Return first 5 rows of the dataset\n",
        "#write code here"
      ],
      "metadata": {
        "id": "Jck1kDcjjVnu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the **info()** method, we can glean more information on the dataset including the names of the different columns and their corresponding data types as well as the number of non-null values.\n",
        "\n"
      ],
      "metadata": {
        "id": "s1fWudV7jX3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Return info on dataset\n",
        "#write code here"
      ],
      "metadata": {
        "id": "CHQct_pQjWD6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Data\n",
        "\n",
        "While our dataset does not appear to have any serious issues, we will nonetheless have to do some basic cleaning and transformation to get it ready for the main EDA task."
      ],
      "metadata": {
        "id": "3CD1CaemjsqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Values\n",
        "\n",
        "We will start by checking the dataset for missing or null values. For this, we can use the `isna()` method which returns a dataframe of boolean values indicating if a field is null or not. To group all missing values by column, we can include the `sum()` method.\n"
      ],
      "metadata": {
        "id": "VUfEd93Tjw67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Display number missing values per column\n",
        "#write code here"
      ],
      "metadata": {
        "id": "rvv93UzzjeQf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have an idea of what data is missing and where. Typically, we have two options: delete rows that contain missing data or replace them with a value. In our case, deleting that many rows may affect our analysis, so we will go ahead and replace the values instead."
      ],
      "metadata": {
        "id": "DRvIX9Glj57b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Several different methods exist for imputing missing values and what works best usually depends on the characteristics of the dataset in question as well as the objective of the analysis. One of the simplest methods is by replacing the null values in each column with the column mean or mode."
      ],
      "metadata": {
        "id": "lT2HGh-Rj85o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will begin with the “credit_score” column. Since credit scores are heavily influenced by one’s income situation, it would be a better idea to impute the missing values in this column based on the mean credit score for the income group an individual belongs in. We can first run a groupby() method to see how the mean values for each income group differ."
      ],
      "metadata": {
        "id": "sgY0-ARfj_dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the mean credit score for each income group\n",
        "#write code here"
      ],
      "metadata": {
        "id": "mNJm9XkukCnv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean credit scores for each group do differ widely as we suspected. We can go ahead and impute the missing values for the “credit_score” column using the mean credit score for each income group. The simplest way to do this would be by creating a function so we don’t have to repeat codes for each income group."
      ],
      "metadata": {
        "id": "5Nxa3tQTkG3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a function to impute missing values based on mean credit score for each income group\n",
        "#write code here"
      ],
      "metadata": {
        "id": "AFEhUrAgkGh6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now apply our custom function to the dataframe.\n",
        "\n"
      ],
      "metadata": {
        "id": "cKfmwIrrkMih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply the function to the dataframe\n",
        "#write code here\n",
        "\n",
        "#check for missing values\n",
        "#write code here"
      ],
      "metadata": {
        "id": "oh9I5KdWkO_S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We no longer have any missing values in the “credit_score” column. We can now tackle the missing values in the “annual_mileage” column. This time, we will do a groupby of the “driving_experience” column and compare the means of each group in the column.\n",
        "\n"
      ],
      "metadata": {
        "id": "VTnH0wOckUSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the mean annual mileage for the different driving experience groups\n",
        "#write code here"
      ],
      "metadata": {
        "id": "4f11c-GxkXTz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unlike the “credit_score” column, the mean for the different groups in the “driving_experience” do not vary too widely so we can simply impute the null values using the column mean.\n",
        "\n"
      ],
      "metadata": {
        "id": "W5QY_nzVkUJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate mean for annual_mileage column\n",
        "#write code here\n",
        "\n",
        "#Fill in null values using the column mean\n",
        "#write code here\n",
        "\n",
        "#Check for null values\n",
        "#write code here"
      ],
      "metadata": {
        "id": "9J2SRNhakffK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We no longer have any null values in our dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "X6MhEiSSkjFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropping Columns\n",
        "\n",
        "Both the `id` and `postal_code` columns will not be relevant for our analysis, so we can get rid of these using the `drop()` method. We will set the `axis` argument to 1 since we’re dealing with columns, and set the `inplace` argument to `True` to make the change permanent.\n"
      ],
      "metadata": {
        "id": "ysIX22ygktgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete the id and postal_code columns\n",
        "#write code here"
      ],
      "metadata": {
        "id": "cgZOv_cEky0B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data preparation section of our project is now complete, and we can shift our attention to our main task, analyzing the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "EnagzQvxkyEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing the Data\n",
        "\n",
        "With our cleansed dataset, we can go ahead and begin the task of exploring the data. While several different analyses exist for EDA, we can group them under three large umbrellas: univariate analysis, bivariate analysis, and multivariate analysis. We will look at each one of these in turn.\n"
      ],
      "metadata": {
        "id": "GofkFBGUlCEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univariate Analysis\n",
        "\n",
        "Univariate analysis is the simplest form of analyzing data. As the name implies, it deals with analyzing data within a single column or variable and is mostly used to describe data. There are different kinds of univariate analyses.\n",
        "\n",
        "**Categorical Unordered**: This type of data has no order or ranking and is categorical as opposed to numerical. Our `gender` column contains two sub-categories that describe whether a client is male or female. We can get a count of each category by using the `value_counts()` method.\n"
      ],
      "metadata": {
        "id": "Uu20tXVGlUSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the count for each category in the \"gender\" column\n",
        "#write code here"
      ],
      "metadata": {
        "id": "2w4xHnE3lcXx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Better yet, we can visualize this information using a countplot from Seaborn.\n",
        "\n"
      ],
      "metadata": {
        "id": "acOwBprtlfvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a countplot to visualize the count of each category in the gender column.\n",
        "#write code here"
      ],
      "metadata": {
        "id": "GMtqSgKjle3a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical ordered**: This type of data has a natural rank and progression. Examples from our dataset include “education” and “income”. Let’s explore the income variable using a pie chart."
      ],
      "metadata": {
        "id": "RZiPf0StloXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define plot size\n",
        "#write code here\n",
        "\n",
        "#Define column to use\n",
        "#write code here\n",
        "\n",
        "#Define labels\n",
        "#write code here\n",
        "\n",
        "#Define color palette\n",
        "#write code here\n",
        "\n",
        "#Create pie chart\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "kqidwwgmlt0f"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The largest category is “upper class”, representing 43% of the total, followed by “middle class” (21%), poverty (18%), and “working class” (17%). Now let’s explore the “education” variable using a countplot.\n",
        "\n"
      ],
      "metadata": {
        "id": "ey-00qxQlw4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a countplot to visualize the count of each category in the education column\n",
        "#write code here\n",
        "\n"
      ],
      "metadata": {
        "id": "ictJf2_Zl3xL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are more clients with a high school education than any other category, followed by university graduates and then clients with no education."
      ],
      "metadata": {
        "id": "QzSg9KK9l2r7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Numeric**: The third type of univariate analysis uses numerical data. Univariate numeric data is usually analyzed by calculating functions like the mean, mode, max, min, standard deviation etc. One easy way to get these summary statistics on a numerical column is by using the describe() method. Let’s try this on the “credit_score” column.\n",
        "\n"
      ],
      "metadata": {
        "id": "QwN89Lw6l7tV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Return summary statistics for the \"credit_score\" column\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "3d2rYVk_mGEt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is great information, but it doesn’t tell us how the data is distributed. A histogram is a great way to visualize the frequency distribution of numerical data. We can plot one using the histplot() function in Seaborn.\n",
        "\n"
      ],
      "metadata": {
        "id": "yqqmiGvymJGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot a histogram using the \"credit_score\" column\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "SSeMLf6gmLPq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The “credit_score” column follows a normal distribution or bell curve. Let’s create another histogram for the “annual_mileage” column, but this time we will include a kernel density estimation (kde) to show smoothness or continuity.\n",
        "\n"
      ],
      "metadata": {
        "id": "tvVxPmAimP9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot a histogram using the \"annual_mileage\" column\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "BwYj7489mT2H"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another bell curve, confirming that data near the mean are more frequent in occurrence than data far from the mean.\n",
        "\n"
      ],
      "metadata": {
        "id": "1PxuYTd8mZWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bivariate analysis\n",
        "Bivariate analysis involves analyzing data with two variables or columns. This is usually a way to explore the relationships between these variables and how they influence each other, if at all. A bivariate analysis could take one of three different forms: numeric-numeric, numeric-categorical and categorical-categorical.\n",
        "\n"
      ],
      "metadata": {
        "id": "KSP11KNKmdPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Numeric-Numeric**: Scatter plots are a common way to compare two numeric variables. Let’s investigate the relationship between “annual_mileage” and “speeding_violations”.\n",
        "\n"
      ],
      "metadata": {
        "id": "x3CAijd5mntp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a scatter plot to. show relationship between \"annual_mileage\" and \"speeding_violations\"\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "SWNJWN7Dmr3K"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the graph, we can infer a negative correlation between annual mileage and the number of speeding violations. This means the more miles a client drives per year, the fewer speeding violations they commit.\n",
        "\n"
      ],
      "metadata": {
        "id": "p6TQAwQ_mu-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could also use a correlation matrix to get more specific information about the relationship between these two variables. A correlation matrix is useful for identifying the relationship between several variables. As an example, let’s create a matrix using the”speeding_violations”, DUIs”, and “past_accidents” columns."
      ],
      "metadata": {
        "id": "irYgUS6lmyHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a correlation matrix to show relationship between select variables\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "FTYvu3qim1em"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All our variables exhibit a positive correlation with each other, meaning when one goes up the other goes up as well and vice-versa. But how do we interpret the strength of this relationship? Generally speaking, a correlation coefficient between 0.5 and 0.7 indicates variables that can be considered moderately correlated, while a correlation coefficient whose magnitude is between 0.3 and 0.5 indicates variables that exhibit weak correlation, as is the case with most of our variables. This means a moderate, positive correlation exists between the number of past accidents and speeding violations, while a weak, positive correlation exists between the number of past accidents and DUIs."
      ],
      "metadata": {
        "id": "-RHBVsTam5if"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best way to visualize correlation however, is with a heatmap. We can easily create one by passing the correlation matrix into the heatmap() function in Seaborn.\n",
        "\n"
      ],
      "metadata": {
        "id": "C-ibnwaUm8ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a heatmap to visualize correlation\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "mPpcdmXsm49r"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Numeric-Categorical**: Here, we analyze data using one set of numeric variables and another set of categorical variables. Analysis can be done by using the mean and median as in the example below. We first group by “outcome” and then calculate the mean “annual_mileage” for each group.\n",
        "\n"
      ],
      "metadata": {
        "id": "BYFxaizinEWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the mean annual mileage per category in the outcome column\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "TM7yU40qnHyW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this method, we could return the minimum, maximum, or median annual mileage for each category by using the min(), max(), and median() methods respectively. However, we can better visualize the difference in dispersion or variability between two variables by using box plots. Box plots display a five-number summary of a set of data; the minimum, first quartile, median, third quartile, and maximum.\n",
        "\n"
      ],
      "metadata": {
        "id": "iEvnkeRJnK-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot two boxplots to compare dispersion\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "9lP6Vd6GnIMK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both variables have similar medians (denoted by the middle line that runs through the box) though clients who made a claim have slightly higher median annual mileage than clients who didn’t. The same can be said for the first and third quartiles (denoted by the lower and upper borders of the box respectively).\n",
        "\n"
      ],
      "metadata": {
        "id": "Rt4aNnSBnP8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, we can compare the distributions of the two categories in “outcome” based on their credit scores, but this time we’ll make use of a bivariate histogram by setting the “hue” argument in the histplot() function to “outcome”.\n",
        "\n"
      ],
      "metadata": {
        "id": "cC-KVh9unZzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create histograms to compare distribution\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "Yh5zNXNdnfln"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical-Categorical**: As you may have guessed by now, this involves a set of two categorical variables. As an example, we will explore how the “outcome” variable relates to categories like age and vehicle year. To begin, we will convert the labels in the outcome column from True and False to 1s and 0s respectively. This will allow us to calculate the claim rate for any group of clients.\n",
        "\n"
      ],
      "metadata": {
        "id": "EOCodPhpnjb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a new \"claim rate\" column\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "gG96oj2nnix2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Half as many clients made a claim in the past year compared to those who didn’t. Now let’s check how the claim rate is distributed between the different categories of age.\n",
        "\n"
      ],
      "metadata": {
        "id": "IG0VDf9xnpkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the average claim rate per age group\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "TUoaqrnKnpFM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above, it is clear that younger people are more likely to make an insurance claim. We can do the same for “vehicle_year”.\n",
        "\n"
      ],
      "metadata": {
        "id": "haoU10jVnvHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the average claim rate per vehicle year category\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "z09lOCOTnx5U"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clients with older vehicles are much more likely to file a claim. Another way to visualize the claim rate is by using probability bar charts.\n",
        "\n"
      ],
      "metadata": {
        "id": "UgQGYSFJn1BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an empty figure object\n",
        "#write code here\n",
        "\n",
        "#Plot two probability graphs for education and income\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "3ybOjftvn8vI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clients with no education are more likely to file a claim compared to high school and university graduates, while clients in the “poverty” income group are more likely to file a claim, followed by clients in the “working class” and “middle class” categories, in that order.\n",
        "\n"
      ],
      "metadata": {
        "id": "YoD4CSrFn56_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multivariate analysis\n",
        "This comprises data analysis involving more than two variables. A common type of multivariate analysis is the heatmap. Heatmaps provide a fast and simple way for visual recognition of patterns and trends. We can easily check the relationship between variables in our data set like “education” and “income” by using a third variable, claim rate. First, we will create a pivot table."
      ],
      "metadata": {
        "id": "Jc0hyUefoEia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a pivot table for education and income with average claim rate as values\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "9D6FaBsRoIxO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then pass in our pivot table to the heatmap() function in Seaborn.\n",
        "\n"
      ],
      "metadata": {
        "id": "RWxTRPo9oLIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a heatmap to visualize income, education and claim rate\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "dV7B-gfDoPLs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "High school graduates in the poverty income class have the highest claim rate, followed by university graduates in the poverty income class. Clients in the upper class income category with no education have the lowest claim rates.\n",
        "\n"
      ],
      "metadata": {
        "id": "dwtKy5kMoSuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s do the same for driving experience and marital status.\n",
        "\n"
      ],
      "metadata": {
        "id": "A5bcSNcNoU6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create pivot table for driving experience and marital status with average claim rate as values\n",
        "#write code here\n",
        "\n",
        "#Create a heatmap to visualize driving experience, marital status and claim rate\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "nv_62CAToXAG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unmarried individuals with 0–9 years of driving experience are the most likely to file a claim, while married individuals with 30+ years of driving experience are the least likely to file a claim.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZvtsaDqvoZIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let’s create a heatmap to visualize gender, family status, and claim rate.\n",
        "\n"
      ],
      "metadata": {
        "id": "yapWDUfNocAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create pivot table for gender and family status with average claim rate as values\n",
        "#write code here\n",
        "\n",
        "#Create a heatmap to visualize gender, family status and claim rate\n",
        "#write code here\n"
      ],
      "metadata": {
        "id": "-F2114VTodxm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Men without children are the most likely to make a claim while women with children are the least likely to make a claim.\n",
        "\n"
      ],
      "metadata": {
        "id": "zb4Co95rogQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "In this workshop, we have explored the basics of EDA by conducting univariate, bivariate, and multivariate analyses on a dataset. I hope that I was able to clearly illustrate the kinds of issues to tackle, the types of visualizations to create, and the various analyses to do while exploring a dataset. Most important of all, I hope that you have gained some new skills from reading or following along with this article. Thank you very much for sticking around to the end, and if there is anything you need further clarification on, please don’t hesitate to leave a comment. All the best in your data journey!"
      ],
      "metadata": {
        "id": "dPtGeuaBojnN"
      }
    }
  ]
}